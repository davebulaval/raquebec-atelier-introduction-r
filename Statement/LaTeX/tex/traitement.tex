\subsection{Traitement}
Une fois en possession du jeu de données, il fut nécessaire de nettoyer ce dernier pour en rendre son utilisation plus simple selon nos besoins. Parmi les différentes modifications apportées nous retrouvons: \\
\begin{itemize}
	\item Conserver que les observations relatives au aéroports Canadiens
	\item Filtrer les variables qui seront pertinentes dans le cadre de l'analyse que nous menons. 
		\footnote{On ne devrait jamais travailler avec des informations superflues. Faire une pré-sélection de l'information ne fait qu'alléger les traitements et augmente de manière significative la compréhensibilité du programme.}
	\item Alimentation des valeurs manquantes avec des sources de données externes (si possible) ou appliquer un traitement approximatif justifiable en documentant les impacts possibles sur le restant de l'analyse.
\end{itemize}
\vspace{\baselineskip}

\noindent
Nous considérons pertinent d'apporter quelques précisions sur le fonctionnement de R avant d'expliciter les traitements sus-mentionnés. Tout d'abord, R est un langage interprèté orienté objet à caractère fonctionnel optimisé pour le traitement vectoriel. Ces simples mots ne sont pas à prendre à la légère puisque ce n'est qu'en s'appropriant ce mode de penser que les futurs développeurs que vous êtes parviendront à utiliser R dans toute sa puissance, sa simplicité et son élégance. Par sa sémantique objet, R permet de définir des attributs aux objets créés. Comme il sera possible de le voir plus loin, l'accès à ces attributs se fera à l'aide de l'opérateur \texttt{\$}. Vous vous demandez probablement: Comment savoir si nous sommes en présence d'un objet? C'est simple, tout dans R est un objet! Le langage R permet aussi de mimer le paradigme fonctionnel puisque les fonctions (qui sont en fait des objets) sont des valeurs à part entière qui peuvent être argument ou valeur d'une autre fonction. De plus, il est possible de définir des fonctions dites anonymes qui se révèleront très pratiques. Finalement, par son caractère vectoriel, la notion de scalaire n'existe tout simplement pas en R. C'est pour cette raison que l'utilisation de boucles est à proscrire (ou du moins à minimiser le plus possible). En effet, l'utilisation d'une boucle revient en quelque sorte à la création d'un nouveau vecteur et à la mise en place de processus itératifs afin d'exécuter la tâche demandée. Heureusement, par un raisonnement vectoriel, il est très simple de convertir ces traitements sous une forme vectorielle dans la plupart des cas. \cite{Goulet} Pour accéder à une valeur précise d'un vecteur, nous utiliserons l'opérateur \texttt{[]} en spécifiant les indices correspondants aux valeurs désirées, un vecteur booléen d'inclusion/exclusion ou encore un vecteur contenant les noms des attributs nommés qui nous intéressent. \\

\noindent
Avec ces outils en mains, il devient ainsi très facile de filtrer les aéroports canadiens à l'aide de l'attribut que nous avons nommé \emph{country} du data.frame \emph{aiports}. Par un raisonnement connexe, la fonction \emph{subset} nous offre aussi la possibilité de conserver que certaines variables contenues dans une table tout en appliquant des contraintes sur les observations à conserver. Le \autoref{src:Filtrer} dévoile au grand jour la dualité qui peut exister entre la multitude des fonctionnalités présentent en R. \\

\begin{lstlisting}[caption = Filtrer les données,label=src:Filter]
	airportsCanada <- airports[airports$country=='Canada',]
	airportsCanada2 <- subset(airports,country == 'Canada')
	all.equal(airportsCanada,airportsCanada2)

	airportsCanada[is.na(airportsCanada$IATA),c("airportID","name","IATA","ICAO")]
	subset(airportsCanada, is.na(IATA), select = c("airportID","name","IATA","ICAO"))
\end{lstlisting}

\vspace{\baselineskip}
\noindent
Nous ne devons pas être surpris qu'il y ait autant de possibilités différentes de parvenir au même résultat, il s'agit là d'une des principales caractéristiques d'un logiciel libre puisque la responsabilité du développement continu ne dépend plus que d'une seule personne ou entité, mais bien de la communauté d'utilisateurs au complet. Ceci peut toutefois sembler mélangeant pour des nouveaux utilisateurs et la question suivante arrivera assez rapidement lorsque vous commencerez à developper vos propres applications: Quelle est la meilleure manière d'accomplir une tâche X? La bonne réponse est tout aussi décevante que la premisse étant donné que chaque fonction aura été devéloppée dans un besoin précis si ce n'est que de rendre l'utilisation de fonctionnalité de base plus aisée et facile d'approche... C'est pourquoi nous conseillons plutôt d'adopter un mode de penser itératif, créatif et ouvert qui consiste à utiliser les fonctions qui vous semblent, à la fois, les plus simples, les plus versatiles et les plus efficientes. À partir du moment où vous constaterez qu'une de ces trois caractéristiques n'est plus au rendez-vous, il suffira d'amorcer des recherches pour bonifier vos connaissances et améliorer vos techniques. C'est un peu le but de ce document de vous faire faire une visite guidée pour vous offrir un coffre d'outil qui facilitera vos premiers pas en R. \\

\begin{moreInfo}{\emph{subset}}
	Bien que la fonction \emph{subset} simplifie énormément l'écriture de requêtes afin de manipuler des bases de données, celle-ci souffre par le fait même de devenir rapidement innefficiente lors de traitements plus complexes. D'autres packages tels que \emph{dplyr} et \emph{sqldf} divendront dans ces situations des meilleures alternatives. \\
	\url{https://www.rdocumentation.org/packages/raster/versions/2.5-8/topics/subset}
\end{moreInfo}

\noindent
Après avoir fait une présélection des données qui nous seront utiles dans le reste de l'analyse, nous avons constater que certaines variables n'étaient pas toujours totalement alimentées. Tout d'abord, la variable IATA n'était pas toujours définie pour tous les aéroports canadiens contrairement à ICAO. Étant donné la faible proportion des valeurs manquantes et du fait qu'une valeur fictive n'aurait qu'un impact minimal dans le cas de l'analyse, nous avons décider de remplacer les valeurs manquantes par les 3 dernières lettres du code ICAO. En regardant les aéroports canadiens possèdant les deux codes, nous observons que cette relation est respectée dans plus de 80\% des cas. Une autre alternative aurait été de simplement prendre le code ICAO, mais le code IATA semblait beaucoup plus facile d'approche puisqu'il s'agit du code communément utiliser pour le transport des particuliers. \\

\noindent
Les vrais problèmes au niveau des données résidaient davantage dans l'absence d'informations sur les fuseaux horaires de certains aéroports ainsi qu'un accès indirect à la province de correspondance de tous les aéroports. Heureusement, ce genre d'information ne dépend que de l'emplacement de l'entité dans le monde, ce qui rend la tâche beaucoup plus simple lorsque nous avons accès aux coordonnées géospatiales. \\

\begin{moreInfo}{Adresses et coordonnées géospatiales}
	Dans la situation où seule l'adresse de l'entité aurait été disponible, nous aurions été contraint d'utiliser des techniques de géocodage qui permettent de transfomer une adresse en coordonnées longitude/latitude et parfois même altitude. Ce genre de transformation est devenu beaucoup plus accessible avec l'avancement de la technologie et plusieurs APIs sont disponibles gratuitement sur le web pour procéder à ce genre de transformation. Encore une fois, il vaut mieux bien se renseigner pour identifier l'interface qui répondra le mieux à nos besoins en considérant notamment:
	\begin{itemize}
		\item Format de l'intrant
		\item Format de retour
		\item Limitation du nombre de requêtes sur une période de temps donnée
		\item Efficacité de l'outil
		\item Méthode d'interpolation
		\item Précision des valeurs
	\end{itemize}
	\url{https://www.programmableweb.com/news/7-free-geocoding-apis-google-bing-yahoo-and-mapquest/2012/06/21}
\end{moreInfo}

\noindent
Bien que nous savons qu'il est possible de populer les valeurs manquantes à l'aide de données géographiques encore faut-il disposer de ses dites données. Encore une fois, grâce à de bonnes recherches vous parviendrez à trouver une source qui contiendra ce dont vous cherchez ou du moins un élément de réponse qui vous permettra d'en extrapoler la valeur ce qui sera déjà préférable à des données manquantes. Statistiques Canada possède une bibliothèque géographique très garnie et c'est notamment sur leur site que nous avons pris le fichier \emph{.shp} qui définit les provinces et territoires du Canada. \cite{Data:BoundaryFiles} En ce qui concerne les fuseaux horaires, nous avons trouvé ceux-ci sur un site dédié à cette fin qui mentionne ne plus être maintenu à jour, mais dont la dernière mise-à-jour a été fait le 28 mai 2016. Étant donné que les fuseaux horaires n'ont pas tendance à changer souvent dans les pays industrialisés comme le Canada, ceci ne consistait pas en un enjeu majeur. \cite{Data:tzWorlwide} \\

\begin{moreInfo}{ArcGIS et les fichiers \emph{.shp}}
	Le premier fichier ayant l'extension \emph{.shp} fut créé dans le but d'être utilisé conjointement avec la suite de logiciel ArcGIS. Il s'agit de la première suite logiciel commercialisable visant le traitement des données géospatiales. Étant des pionners dans le domaine, plusieurs aspects des outils visant à faire des traitements géospatiaux proviendront directement de leur travaux. Les fichiers \emph{.shp} sont aujourd'hui vu comme un standard pour transporter ce type de donnés. \\
\url{https://www.arcgis.com/features/index.html}
\end{moreInfo}

\noindent
Pour être en mesure de bien travailler avec ce genre de fichier nous devons en comprendre leur fonctionnement. Tout d'abord, lorsque vous téléchargerez un \emph{.zip} de données géospatiales, vous devirez toujours obtenir la structure suivante de fichiers: \\

\addPicture{1}{1}{structureDataGeo}{Structure des fichiers de données géospatiales}{structDataGeo} 

\noindent
Tel qu'illustré à la \autoref{fig:structDataGeo}, un dossier de données géospatiales se divisera minimalement sous la forme de quatre fichiers:
\begin{description}[style=multiline,leftmargin=1.5cm]
	\item[\emph{.shp}] Contient l'information géographique représentée sous la forme de points, segments et/ou polygones
	\item[\emph{.dbf}] Contient l'information ratachée à tous les entités définies dans le \emph{.shp}
	\item[\emph{.prj}] Contient les informations sur la projection associée (le modèle mathétique permettant d'interpréter les informations du \emph{.shp} \cite{projectionSIG})
	\item[{.shx}] Contient les index des enregistrements du \emph{.shp}
\end{description}
Cette structure peut donner l'impression que leur utilisation conjointement avec R sera compliqué, mais c'est loin d'être le cas grâce aux paquetages \emph{rgdal} et \emph{sp}. Pour conclure sur ce point, notons que la désignation \emph{ShapeFile} au sens large désigne l'ensemble de la structure de fichier et non pas seulement le \emph{.shp} lui-même. \cite{portailSIG} \\

\noindent
Le paquetage \emph{rgdal} n'aura qu'une utilité bien précise, soit celle d'aller extraire les informations contenues dans le \emph{ShapeFile}. Cepenant, il possède des dépendances directement dans le paquetage \emph{sp} ce qui explique pourquoi le seul appel de \emph{rgdal} entraîne du même coup l'appel de \emph{sp}. Les rôles de \emph{sp} sont plutôt de transformer les informations des objets R sous une forme compatible au \emph{ShapeFile} que nous aurons lu. Notez bien la transformation de la projection sous une base commune en passant ainsi de \emph{NA} vers \begin{verbatim} "+proj=longlat" \end{verbatim} (projection choisie en fonction des données contenues) à \begin{verbatim} "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0" \end{verbatim} soit la projection du \emph{ShapeFile}. La nécessité que nos points soit sous la même projection que celle du \emph{ShapeFile} provient du fait que nous voulons superposer ces derniers pour ensuite en extraire l'information correspondante. Les deux fonctions indispensables ici sont \emph{CRS} qui retourne un objet de classe \emph{Coordinate Reference System} à partir d'une chaîne de caractère passée en argument et \emph{over} qui se chargera de faire la superposition de points géométriques sur un couche (correspondant ici au \emph{ShapeFile} vu selon une certaine projection) qui contient les attributs envers lesquels nous avons un intérêt. Le retour de la fonction \emph{over} sera finalement un \emph{data.frame} de même longueur que le nombre de points donnés en argument que nous pourrons facilement combiner le jeu de données initial. Cette recette ne risque pas de varier beaucoup d'un ShapeFile à un autre vous pourrez donc litéralement reprendre le code ci-dessous. \\

\begin{lstlisting}[caption = Filtrer les données,label=src:Filter]
	# Step 1 - Import the Packages	
	library(sp)
	library(rgdal)
	# Step 2 - Read the ShapeFile
	prov_terr.shape <- readOGR(dsn=paste(path,"/Reference/prov_terr",sep=""),layer="gpr_000b11a_e")
	# Step 3 - Create the Spatial Points to be overlaid
	unknown_prov <- airportsCanada[,c("airportID","city","longitude","latitude")]
	sppts <- SpatialPoints(unknown_prov[,c("longitude","latitude")])
	# Step 4 - Set the Spatial Points on the same projection as the ShapeFile
	proj4string(sppts) <- CRS("+proj=longlat")
	sppts <- spTransform(sppts, proj4string(prov_terr.shape))
	# Step 5 - Extract the Desired Information by overlaying the Spatial Points on the ShapeFile
	merged_prov <- cbind(airportsCanada,over(sppts,prov_terr.shape))
\end{lstlisting}

\vspace{\baselineskip}
\noindent
Maintenant que nous disposons de l'information requise pour compléter notre base de données, nous devons combiner la table primaire avec les sous-tables crées lors de nos extractions et refaire un dernier filtre final pour se débarasser de tout ce qui ne sera plus utile. Bien que les fonctionnalités de base de R vous permettrait d'accomplir la tâche, nous profitons de cette étape du processus pour vous introduire les paquetages \emph{sqldf} et \emph{dplyr}. \\

\noindent
Le langage SQL (\emph{Structured Query Language}) fut inventé en 1974 et ce dernier fut normalisé en 1986 devenant aisni un standard dans l'exploitation de base de données relationnelles. Devenir familier avec les langages normalisés tel que le SQL ne peut qu'être à votre avantage puisque ceux-ci vous permettront d'écrire des tronçons de code qui pourront facilement être transportés avec peu de modifications d'un environnement à un autre. Leur caractère normalisé impose aux environnements voulant respecter les standards de l'industrie d'être en mesure de compiler ces instructions bien qu'il y ait des fonctionnalités permettant de répliquer leur comportement ou du moins offrir un paquetage permettant leur interprétation. \cite{SQL} Nous conseillons fortement à tous les analystes de données de s'approprier les rudiments du SQL très tôt dans leur cheminement en raison de sa simplicité et sa flexibilité. Les requêtes SQL sont habituellement constituées des quatres instructions suivantes: \\

\begin{description}[style=multiline,leftmargin=2cm]
	\item[Select] Déclare les variables que nous voulons conserver
	\item[From] Indique la source des données
	\item[Where] Mentionne les conditions que les observations doivent respecter pour se retrouver dans l'extrant
	\item[Order by] Spécifie la manière de trier l'extrant
\end{description}

\noindent
La syntaxe rudimentaire rend sa compréhension presque immédiate, et ce, même à des personnes ignorant même qu'il s'agit en fait d'une requête SQL. Dépendemment des noms de variables contenues dans les relations exploitées, les requêtes peuvent parfois se lire aussi bien qu'une liste d'épicerie écrite en anglais. Le \autoref{src:simpleSQL} fourni un exemple de l'utilisation du langage SQL avec R rendu disponible par le paquetage \emph{sqldf}.

\begin{lstlisting}[caption = Exemple de requête SQL,label=src:simpleSQL]
library(sqldf)
sqldf("SELECT name,IATA,altitude,province
      FROM airportsCanada
      WHERE province = 'New Brunswick'
      ORDER BY name")
\end{lstlisting}

\vspace{\baselineskip}
\noindent
En nous fiant à la requête ci-dessus, nous pourrions la transformer de manière textuelle sous la forme suivante:
\begin{enumerate}
	\item Sélectionne les variables \emph{name, IATA, altitude et province}
	\item Dans la relation \emph{airportsCanada}
	\item Dont la province est \emph{New Brunswick}
	\item En triant le tout par \emph{name}
\end{enumerate}

\noindent
Toutefois, les fonctionnalités de SQL ne s'arrête pas ici. Grâce à des intructions très compactes, nous pourrons rendre le comportement de la requête bien plus complexe. Parmi les fonctionnalités qui font partie de notre quotidien, nous retrouvons \emph{*} qui lorsqu'utiliser au sein de l'instruction \emph{select} permettra d'extraire l'ensemble des variables de la relation sans avoir à les écrire une à la fois. La fonction \emph{coalesce} servira à extraire la première valeur non manquante parmi une liste de variables fournie en argument. Nous attirons au passage votre attention sur le mot clé \emph{as} qui a pour effet d'attribut un nom à l'expression sous-jacente. Finalement, le bon vieux \emph{left join} rendant si simple la fusion conditionnelle de deux tables en conservant toutefois les observations de la relation mère malgré le fait qu'il n'y ait pas eu correspondance dans la table à fusionner. Les conditions de cette fusion seront explicitées avec l'instruction \emph{on} qui n'aura pas de signification tangible sans la présence de \emph{join}. Le \autoref{src:advancedSQL} présente une requête combinant tous ces fonctionnalités que vous serez en mesure de retrouver dans le code source du projet.

\begin{lstlisting}[caption = Fonctionnalités avancées de SQL,label=src:advancedSQL]
airportsCanada <- sqldf("
  SELECT 
    a.*, 
    COALESCE(a.tzFormat,b.TZID) AS tzMerged,
    c.PRENAME AS provMerged
  FROM airportsCanada a 
  LEFT JOIN merged_tz b
  	ON a.airportID = b.airportID
  LEFT JOIN merged_prov c
  	ON a.airportID = c.airportID
  ORDER BY a.airportID")
\end{lstlisting}

\vspace{\baselineskip}
\noindent
Il serait faux de dire que ceci correspond à une bonne introduction à SQL sans parler de la capacité d'imbriquer des requête SQL. C'est à ce moment que toute la puissance du langage se révèle à nous. Le \autoref{src:interlinkedSQL} montre un exemple standard d'imbrication qui a été exploité pour créer la relation \emph{routesCanada} en ne conservant que les routes aériennes empruntées pour les vols internes au Canada. \footnote{Le mot clé \emph{DISTINCT} spécifie de ne conserver qu'une seule observation pour chaque modalité retrouvée} \footnote{L'utilisation de la case dans les exemples n'a été utilisé que pour bien faire la différence entre les instructions SQL des informations spécifiques aux relations traitées. Le SQL n'est pas sensible à la case.}

\begin{lstlisting}[caption = Fonctionnalités avancées de SQL,label=src:interlinkedSQL]
routesCanada <- sqldf("
  SELECT *
  FROM routes
  WHERE sourceAirportID IN (SELECT DISTINCT airportID
                            FROM airportsCanada)
    AND destinationAirportID IN (SELECT DISTINCT airportID
                                 FROM airportsCanada)")                           
\end{lstlisting}

\begin{moreInfo}{\emph{Structured Query Language} (SQL)}
	Le langage SQL regorge de plusieurs autres fonctionnalités qui ne seront pas abordées dans ce document. Parmi ces dernières, nous retrouvons \emph{GROUP BY}, \emph{HAVING}, les fonctions d'aggrégation numérique tel quel \emph{SUM}, \emph{AVG}, \emph{MIN}, \emph{MAX}, etc. et nous pourrions continuer ainsi encore longtemps. \\
	\url{https://www.w3schools.com/sql/}
\end{moreInfo}

\noindent
Avant de passer à la prochaine section, il serait injuste de présenter \emph{sqldf} avec autant de précisions sans toucher un mot sur les paquetages \emph{plyr} et \emph{dplyr}. Ces derniers visent à reproduire les opérations permises par le langage SQL avec une notation aussi simpliste, mais en optimisant ces opérations en tenant compte du fonctionnement intrinsèque de R, soit le calcul matriciel. Une différence majeure avec le SQL provient du mode de pensée se rapprochant davantage d'un mode procédural pour \emph{plyr} que du mode fonctionnel pour le SQL. Ces packages deviendront des outils très pertinents lorsque vous commencerez à faire face à des problèmes de temps d'exécution inraisonables.

\begin{moreInfo}{\emph{plyr} ou \emph{dplyr} ?}
	Le paquetage \emph{dplyr} est en fait une seconde version du paquetage \emph{plyr} visant à optimiser le temps de calcul, simplifier son utilisation à l'aide d'une syntaxe plus intuitive et à rendre ses fonctions plus cohérentes entre elles. De plus, \emph{dplyr} concentre son développement autour de la classe object \emph{data.frame}. Pour toutes ces raisons, l'utilisation de \emph{dplyr} serait à préconiser si vous travaillez avec des \emph{data.frame} qui consistent du même coup en la classe standard de R pour représenter les bases de données...\\
	\url{https://blog.rstudio.org/2014/01/17/introducing-dplyr/}
\end{moreInfo}