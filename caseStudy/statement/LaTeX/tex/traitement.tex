\subsection{Traitement}
\label{subsec:Traitement}

Une fois en possession du jeu de données, il est nécessaire de nettoyer ce dernier pour rendre son utilisation plus simple. Parmi les différentes modifications apportées, nous retrouvons: \\
\begin{itemize}
	\item Conserver les observations relatives aux aéroports canadiens.
	\item Filtrer les variables qui seront pertinentes à l'analyse que nous menons. 
		\footnote{On ne devrait jamais travailler avec des informations superflues. Faire une présélection de l'information ne fait qu'alléger les traitements et augmente de manière significative la compréhensibilité du programme.}
	\item Alimenter les valeurs manquantes avec des sources de données externes (si possible) ou appliquer un traitement approximatif justifiable en documentant les impacts possibles sur le reste de l'analyse.
\end{itemize}
\vspace{\baselineskip}

Nous considérons pertinent d'apporter quelques précisions sur le fonctionnement de R avant d'expliciter les traitements susmentionnés. Tout d'abord, R est un langage interprété orienté objet à caractère fonctionnel optimisé pour le traitement vectoriel. Ces simples mots ne sont pas à prendre à la légère puisque ce n'est qu'en s'appropriant ce mode de penser que les futurs développeurs que vous êtes parviendront à utiliser R dans toute sa puissance, sa simplicité et son élégance. \\

Par sa sémantique objet, R permet de définir des attributs aux objets créés. L'accès à ces attributs se fera grâce à des fonctions définies à cet effet. Comme il sera possible de le voir plus loin, l'opérateur \texttt{\$} servira aussi à l'accès aux attributs dans le cas particulier où l'objet manipulé sera de mode \texttt{list}.
Vous vous demandez probablement: Comment savoir si nous sommes en présence d'un objet? C'est simple, tout dans R est un objet! \\

\begin{moreInfo}{\texttt{\$} et le \texttt{data.frame}}
	Nous ne serons pas étonnés d'apprendre que l'opérateur \texttt{\$} nous permettra d'extraire des variables d'un \texttt{data.frame}. Comme nous l'avons préciser à la \autoref{subsec:extraction}, un \texttt{data.frame} n'est rien d'autre qu'une liste de vecteurs.
\end{moreInfo}

Le langage R permet aussi de mimer le paradigme fonctionnel puisque les fonctions (qui sont en fait des objets) sont des valeurs à part entière qui peuvent se retrouver en argument ou en valeur de retour d'une autre fonction. De plus, il est possible de définir des fonctions dites anonymes qui se révèleront très pratiques. À ce sujet, les personnes habituées au paradigme procédural, présent dans les langages comme \emph{SAS} ou \emph{VBA}, devront s'habituées à l'évaluation d'une expression de son point central vers l'extérieur au lieu du chemin traditionnel allant du début vers la fin. \\

Finalement, par son caractère vectoriel, la notion de scalaire n'existe tout simplement pas en R. C'est pour cette raison que l'utilisation de boucles est à proscrire (ou du moins à minimiser le plus possible). En effet, l'utilisation d'une boucle revient en quelque sorte à la création d'un nouveau vecteur et à la mise en place de processus itératifs afin d'exécuter la tâche demandée. Heureusement, ces traitements pourront être convertis sous une forme vectorielle dans la plupart des cas. \cite{Goulet} Pour accéder à une valeur précise d'un vecteur, nous utiliserons l'opérateur \texttt{[]} en spécifiant les indices correspondants aux valeurs désirées, un vecteur booléen d'inclusion/exclusion ou encore un vecteur contenant les noms des attributs nommés qui nous intéressent. \\

Avec ces outils en mains, il devient très facile de filtrer les aéroports canadiens à l'aide de la variable que nous avons nommée \emph{country} du \texttt{data.frame} \texttt{airports}. Par un raisonnement connexe, la fonction \texttt{subset} \cite{Rfunction:subset} offre la possibilité de ne conserver que certaines variables tout en appliquant des contraintes sur ces dernières. Le \autoref{src:Filtrer} dévoile au grand jour la dualité qui peut exister entre la multitude de fonctions présentent en R. \\

\begin{lstlisting}[caption = Filtrer les données,label=src:Filter]
	airportsCanada <- airports[airports$country=="Canada",]
	airportsCanada2 <- subset(airports,country == "Canada")
	all.equal(airportsCanada,airportsCanada2)

	airportsCanada[is.na(airportsCanada$IATA),c("airportID","name","IATA","ICAO")]
	subset(airportsCanada, is.na(IATA), select = c("airportID","name","IATA","ICAO"))
\end{lstlisting}

\vspace{\baselineskip}
Nous ne devons pas être surpris qu'il y ait autant de possibilités différentes de parvenir au même résultat. Il s'agit là d'une des principales caractéristiques d'un logiciel libre, puisque la responsabilité du développement continu ne dépend plus que d'une seule personne ou entité, mais bien de la communauté d'utilisateurs au complet. Ceci peut toutefois sembler mélangeant pour des nouveaux utilisateurs et la question suivante arrivera assez rapidement lorsque vous commencerez à développer vos propres applications: Quelle est la meilleure manière d'accomplir cette tâche? La bonne réponse est tout aussi décevante que la prémisse étant donné que chaque fonction aura été développée dans un but précis tel que faciliter l'utilitisation et la compréhensibilité de fonctionnalités de base... C'est pourquoi nous conseillons d'adopter un mode de pensée itératif, créatif et ouvert qui consiste à utiliser les fonctions qui vous semblent, à la fois, les plus simples, versatiles et efficientes. À partir du moment où vous constaterez qu'une de ces trois caractéristiques n'est plus au rendez-vous, il suffira d'amorcer des recherches pour bonifier vos connaissances et améliorer vos techniques. Ce document vous permettra de consolider vos premiers apprentissages et de bâtir un coffre d'outils qui facilitera vos premiers pas en R. \\

\begin{moreInfo}{\texttt{subset}}
	Bien que la fonction \texttt{subset} simplifie énormément l'écriture de requêtes afin de manipuler des bases de données, celle-ci souffre par le fait même de devenir rapidement inefficiente lors de traitements plus complexes. D'autres paquetages tels que \texttt{dplyr} et \texttt{sqldf} deviendront dans ces situations des alternatives beaucoup plus efficientes. \\
	\url{https://www.rdocumentation.org/packages/raster/versions/2.5-8/topics/subset}
\end{moreInfo}

Après avoir fait une présélection des données qui nous seront utiles dans le reste de l'analyse, nous avons constaté que certaines variables n'étaient pas complètes. Tout d'abord, la variable \emph{IATA} n'était pas toujours définie contrairement à la variable \emph{ICAO}. Étant donné la faible proportion des valeurs manquantes et du fait qu'une valeur fictive n'aurait qu'un impact minimal dans le cas de l'analyse, nous avons décidé de remplacer les valeurs manquantes par les 3 dernières lettres du code \emph{ICAO}. En regardant les aéroports canadiens possédant les deux codes, nous observons que cette relation est respectée dans plus de 80\% des cas. Une autre alternative consistait à simplement prendre le code \emph{ICAO}, mais le code \emph{IATA} nous semblait plus universel. \footnote{Il s'agit du code communément utiliser pour le transport des particuliers.} \\

Le vrai problème au niveau des données résidait dans l'absence d'informations sur les fuseaux horaires de certains aéroports ainsi qu'un accès indirect à la province de correspondance de tous les aéroports. Heureusement, ce genre d'information ne dépend que de l'emplacement de l'entité dans le monde, ce qui rend la tâche beaucoup plus simple lorsque nous avons accès aux coordonnées géospatiales. \\

\begin{moreInfo}{Adresses et coordonnées géospatiales}
	Dans la situation où seule l'adresse de l'entité aurait été disponible, nous aurions été contraints d'utiliser des techniques de géocodage qui permettent de transformer une adresse en coordonnées longitude/latitude et parfois même altitude. Ce genre de transformation est devenu beaucoup plus accessible avec l'avancement de la technologie et la création de plusieurs \emph{Application Programming Interface} (API) disponibles gratuitement sur le web. Encore une fois, il vaut mieux bien se renseigner pour identifier l'interface qui répondra le mieux à nos besoins en considérant notamment:
	\begin{itemize}
		\item Format de l'intrant
		\item Format de l'extrant
		\item Limitation du nombre de requêtes sur une période de temps donnée
		\item Efficacité de l'outil
		\item Méthode d'interpolation
		\item Précision des valeurs
	\end{itemize}
	\url{https://www.programmableweb.com/news/7-free-geocoding-apis-google-bing-yahoo-and-mapquest/2012/06/21}
\end{moreInfo}

Bien qu'il soit possible de combler les valeurs manquantes à l'aide de données géographiques, il est indispensable de disposer de ces dites données. Encore une fois, grâce à de bonnes recherches, vous parviendrez à trouver une source qui contiendra ce dont vous cherchez ou du moins un élément de réponse qui permettra d'en extrapoler la valeur. Statistiques Canada possède une bibliothèque géographique très garnie et c'est notamment sur leur site que nous avons pris le fichier \texttt{.shp} qui définit les provinces et territoires du Canada. \cite{Data:BoundaryFiles} En ce qui concerne les fuseaux horaires, nous avons initialement trouvé ceux-ci sur un site \cite{Data:tzWorldwide} dédié à cette fin qui mentionne ne plus être maintenu à jour, mais dont la dernière mise à jour a été faite le 28 mai 2016. \footnote{Les fuseaux horaires n'ont pas tendance à changer souvent dans les pays industrialisés comme le Canada, ceci ne consistait donc pas en un enjeu majeur.} En approfondissant nos recherches, nous sommes tombés sur un projet \emph{GitHub} visant à 
créer un outil pour extraire l'information d'\emph{Open Street Map} (OSM) pour construire un \emph{ShapeFile} des fuseaux horaire mondiaux incluant les eaux territoriales. \cite{timezone-boundary-builder} \footnote{Les impacts de ce changement seront mineurs dans le cadre de notre étude se concentrant sur les aéroports canadiens. Vous référez à l'\autoref{ann:contribOpenFlights} pour plus d'informations sur les raisons de ce changement.} \\

\begin{moreInfo}{ArcGIS et les fichiers \texttt{.shp}}
	Le premier fichier ayant l'extension \texttt{.shp} fut créé dans le but d'être utilisé conjointement avec la suite de logiciel ArcGIS. Il s'agit du premier logiciel commercialisable visant le traitement des données géospatiales. Étant des pionniers dans le domaine, plusieurs aspects des outils visant à faire des traitements géospatiaux proviendront directement de leurs travaux. Les fichiers \texttt{.shp} sont aujourd'hui vus comme un standard pour contenir ce type d'information. \\
\url{https://www.arcgis.com/features/index.html}
\end{moreInfo}

Pour être en mesure de travailler avec ce genre de fichier, nous devons en comprendre leur fonctionnement. Tout d'abord, lorsque vous téléchargerez un \texttt{.zip} de données géospatiales, vous devrez toujours obtenir la structure suivante de fichiers: \\

\addPicture{1}{1}{structureDataGeo}{Structure des fichiers de données géospatiales}{structDataGeo} 

Tel qu'illustré à la \autoref{fig:structDataGeo}, un dossier de données géospatiales se divisera minimalement sous la forme de quatre fichiers:
\begin{description}[style=multiline,leftmargin=1.5cm]
	\item[\texttt{.shp}] Contient les entités géographiques représentées sous la forme de points, segments et/ou polygones.
	\item[\texttt{.dbf}] Contient les données rattachés à toutes les entités définies dans le \texttt{.shp}.
	\item[\texttt{.prj}] Contient les informations sur la projection utilisée (le modèle mathématique permettant d'interpréter les informations du \texttt{.shp} \cite{projectionSIG}).
	\item[{.shx}] Contient les index des enregistrements du \texttt{.shp}.
\end{description}
Cette structure peut donner l'impression que son utilisation conjointe à R sera compliquée, mais c'est loin d'être le cas grâce aux paquetages \texttt{rgdal} \cite{Rpackage:rgdal} et \texttt{sp}\cite{Rpackage:sp} . Pour conclure sur ce point, notons que la désignation \emph{ShapeFile} au sens large désigne l'ensemble de la structure de fichier et non pas seulement le \texttt{.shp} lui-même. \cite{portailSIG} \\

Le paquetage \texttt{rgdal} n'aura qu'une utilité bien précise, soit celle d'extraire les informations contenues dans le \emph{ShapeFile}. Cependant, il possède des dépendances au paquetage \texttt{sp} ce qui explique pourquoi le seul appel de \texttt{rgdal} entraîne du même coup l'appel de \texttt{sp}. Les rôles de \texttt{sp} sont plutôt de transformer les informations des objets R sous une forme compatible au \emph{ShapeFile} que nous aurons lu. Notez bien la transformation de la projection sous une base commune en passant ainsi de \texttt{NA} vers \begin{verbatim} "+proj=longlat" \end{verbatim} (projection choisie en fonction des données contenues) à \begin{verbatim} "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0" \end{verbatim} soit la projection du \emph{ShapeFile} que nous cherchons à combiner. La nécessité que nos points soient sous la même projection que celle du \emph{ShapeFile} vient du fait que nous voulons superposer ces derniers pour ensuite en extraire l'information correspondante. Les deux fonctions indispensables sont \texttt{CRS}, qui retourne un objet de classe \emph{Coordinate Reference System} à partir d'une chaîne de caractères passée en argument, et \texttt{over}, qui se chargera de faire la superposition des points géographiques sur une couche donnée. Le retour de la fonction \texttt{over} sera finalement un \texttt{data.frame} de dimension équivalente au nombre de points fournis en argument que nous pourrons facilement combiner avec le jeu de données initial. Cette recette ne risque pas de varier beaucoup d'un \emph{ShapeFile} à un autre, vous pourrez donc littéralement reprendre le code ci-dessous. \\

\begin{lstlisting}[caption = Traitement standard de données géospatiales en R,label=src:GeoDataR]
	# Step 1 - Import the packages	
	library(sp)
	library(rgdal)
	# Step 2 - Read the ShapeFile
	prov_terr.shape <- readOGR(dsn=paste(path,"/Reference/prov_terr",sep=""),layer="gpr_000b11a_e")
	# Step 3 - Create the Spatial Points to be overlaid
	unknown_prov <- airportsCanada[,c("airportID","city","longitude","latitude")]
	sppts <- SpatialPoints(unknown_prov[,c("longitude","latitude")])
	# Step 4 - Set the Spatial Points on the same projection as the ShapeFile
	proj4string(sppts) <- CRS("+proj=longlat")
	sppts <- spTransform(sppts, proj4string(prov_terr.shape))
	# Step 5 - Extract the desired information by overlaying the Spatial Points on the ShapeFile layer
	merged_prov <- cbind(airportsCanada,over(sppts,prov_terr.shape))
\end{lstlisting}

\vspace{\baselineskip}
Maintenant que nous disposons de toute l'information requise pour compléter notre base de données, nous devons combiner la table primaire avec les sous-tables créées lors de nos extractions et refaire un dernier filtre pour se débarrasser de tout ce qui ne sera plus utile. Bien que les fonctionnalités de base de R vous permettent d'accomplir la tâche, nous profitons de cette étape du processus pour vous présenter les paquetages \texttt{sqldf} \cite{Rpackage:sqldf} et \texttt{dplyr} \cite{Rpackage:plyr}. \\

\begin{moreInfo}{Normaliser la marginalité}
	Le langage SQL (\emph{Structured Query Language}) fut inventé en 1974 et ce dernier fut normalisé en 1986 devenant ainsi un standard dans l'exploitation des bases de données relationnelles. \\
	\url{https://fr.wikipedia.org/wiki/Structured_Query_Language}
\end{moreInfo}

Devenir familier avec les langages normalisés tels que le SQL ne peut être qu'à votre avantage puisque ceux-ci vous permettront d'écrire des tronçons de code qui pourront facilement être transportés d'un environnement à un autre avec peu de modifications. Leur caractère normalisé impose aux environnements voulant respecter les standards de l'industrie d'être en mesure d'interpréter ces instructions qu'il y ait ou non des fonctionnalités permettant de répliquer leur comportement. \footnote{Minimalement, offrir un paquetage permettant leur interprétation.} \cite{SQL} Nous conseillons fortement à tous les analystes de données de s'approprier les rudiments du SQL très tôt dans leur cheminement en raison de sa simplicité et sa flexibilité. Les requêtes SQL sont habituellement constituées des quatre instructions suivantes: \\

\begin{description}[style=multiline,leftmargin=2cm]
	\item[Select] Déclare les variables que nous voulons conserver
	\item[From] Indique la source des données
	\item[Where] Mentionne les conditions que les observations doivent respecter pour se retrouver dans l'extrant
	\item[Order by] Spécifie la manière de trier l'extrant
\end{description}

La syntaxe du SQL, qui se rapproche énormément d'une phrase complète et structurée, rend sa compréhension presque immédiate, et ce, même à des personnes ignorant qu'il s'agit en fait d'une requête SQL. Dépendamment des noms de variables contenues dans les relations exploitées, les requêtes peuvent parfois se lire aussi bien qu'une liste d'épicerie écrite en anglais. Le \autoref{src:simpleSQL} fournit un exemple de l'utilisation du langage SQL avec R rendu disponible par le paquetage \texttt{sqldf}.

\begin{lstlisting}[caption = Exemple de requête SQL,label=src:simpleSQL]
library(sqldf)
sqldf("SELECT name,IATA,altitude,province
      FROM airportsCanada
      WHERE province = 'New Brunswick'
      ORDER BY name")
\end{lstlisting}

\vspace{\baselineskip}
La requête ci-dessus pourrait être transformée de manière textuelle sous la forme suivante:
\begin{enumerate}
	\item Sélectionne les variables \texttt{name, IATA, altitude et province}
	\item Dans la relation \texttt{airportsCanada}
	\item Dont la province est \emph{New Brunswick}
	\item En triant le tout par \emph{name}
\end{enumerate}

Toutefois, les fonctionnalités de SQL ne s'arrêtent pas ici. Grâce à des instructions très compactes, nous pourrons rendre le comportement de la requête bien plus complexe. Parmi les fonctionnalités qui feront parties de notre quotidien, nous retrouverons \texttt{*} qui, lorsque placé dans l'instruction \texttt{select}, permettra d'extraire l'ensemble des variables de la relation sans avoir à les écrire une à une. La fonction \texttt{coalesce} servira à extraire la première valeur non manquante parmi une liste de variables fournies en argument. Nous attirons au passage votre attention sur le mot clé \texttt{as} qui a pour effet d'attribuer un nom à l'expression sous-jacente. Finalement, le bon vieux \texttt{left join} rendant si simple la fusion conditionnelle de deux tables en conservant les observations de la relation mère \footnote{La relation se situant à la gauche dans le merge.} même s'il n'y a pas eu correspondance dans la table à fusionner. Les conditions de cette fusion seront explicitées avec l'instruction \texttt{on} qui n'aura pas de signification tangible sans la présence de \texttt{join}. Le \autoref{src:advancedSQL} présente une requête combinant toutes ces fonctionnalités.

\begin{lstlisting}[caption = Fonctionnalités avancées de SQL,label=src:advancedSQL]
airportsCanada <- sqldf("
  SELECT 
    a.*, 
    COALESCE(a.tzFormat,b.TZID) AS tzMerged,
    c.PRENAME AS provMerged
  FROM airportsCanada a 
  LEFT JOIN merged_tz b
  	ON a.airportID = b.airportID
  LEFT JOIN merged_prov c
  	ON a.airportID = c.airportID
  ORDER BY a.airportID")
\end{lstlisting}

\vspace{\baselineskip}
Il serait faux de dire que ceci correspond à une bonne introduction à SQL sans parler de la capacité d'imbriquer des requêtes. C'est à ce moment que toute la puissance du langage se révèle à nous. Le \autoref{src:interlinkedSQL} montre un exemple standard d'imbrication qui a été exploité pour créer la relation \texttt{routesCanada} en ne conservant que les routes empruntées pour les vols internes au Canada. \footnote{Le mot clé \texttt{distinct} spécifie de ne conserver qu'une seule observation pour chaque modalité retrouvée.} \footnote{L'utilisation de la case dans les exemples ne sert qu'à bien faire la différence entre les instructions SQL des informations spécifiques aux relations traitées. Le SQL n'est pas sensible à la case.}

\begin{lstlisting}[caption = Fonctionnalités avancées de SQL,label=src:interlinkedSQL]
routesCanada <- sqldf("
  SELECT *
  FROM routes
  WHERE sourceAirportID IN (SELECT DISTINCT airportID
                            FROM airportsCanada)
    AND destinationAirportID IN (SELECT DISTINCT airportID
                                 FROM airportsCanada)")                           
\end{lstlisting}

\begin{moreInfo}{\emph{Structured Query Language} (SQL)}
	Le langage SQL regorge de plusieurs autres possibilités qui ne seront pas abordées dans ce document. Parmi ces dernières, nous retrouvons \texttt{group by}, \texttt{having}, les fonctions d'agrégation numérique tel quel \texttt{sum}, \texttt{avg}, \texttt{min}, \texttt{max}, etc. et nous pourrions continuer ainsi encore longtemps. \\
	\url{https://www.w3schools.com/sql/}
\end{moreInfo}

Avant de passer à la prochaine section, il serait injuste de présenter \texttt{sqldf} avec autant de précisions sans toucher un mot sur les paquetages \texttt{plyr} et \texttt{dplyr}. Ces derniers visent à reproduire les opérations permises par le langage SQL avec une notation aussi simpliste, mais en optimisant ces opérations pour prendre en compte le fonctionnement intrinsèque de R, soit le calcul vectoriel. Une différence majeure avec le SQL provient du mode de pensée se rapprochant davantage d'un mode procédural pour \texttt{plyr} que du mode fonctionnel pour le SQL. Ces paquetages deviendront des outils très pertinents lorsque vous commencerez à faire face à des temps d'exécution irraisonnables. \cite{dplyrVSsqldf}

\begin{moreInfo}{\texttt{plyr} ou \texttt{dplyr} ?}
	Le paquetage \texttt{dplyr} est en fait une seconde version du paquetage \texttt{plyr} visant à optimiser le temps de calcul, à simplifier son utilisation à l'aide d'une syntaxe plus intuitive et à rendre ses fonctions plus cohérentes entre elles. De plus, \texttt{dplyr} concentre son développement autour de la classe object \texttt{data.frame}. Pour toutes ces raisons, l'utilisation de \texttt{dplyr} serait à préconiser si vous travaillez avec des \texttt{data.frame} qui consistent du même coup en la classe standard de R pour représenter les bases de données...\\
	\url{https://blog.rstudio.org/2014/01/17/introducing-dplyr/}
\end{moreInfo}