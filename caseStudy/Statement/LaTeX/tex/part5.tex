En plus des capacités statistiques impressionnantes que nous avons survolées à la section précédente, R dispose d'une vaste gamme d'outils d'optimisation. Pour ne pas trop nous écarter du but premier de cette documentation, soit de faire une revue globale des fonctionnalités de R en utilisant une étude de cas à titre de support de présentation, nous concentrerons la discussion autour des fonctions \texttt{optim} \cite{Rfunction:optim} et \texttt{fitdistr} \cite{Rfunction:fitdistr}. Nous terminerons en présentant comment répliquer le comportement de la fonction \texttt{fitdistr} dans le cadre d'une fonction utilitaire. \\

La fonction \texttt{optim} est un excellent choix de fonction pour aborder tout problème d'optimisation. Contrairement à bien d'autres outils, cette fonction permettra d'optimiser plusieurs paramètres à la fois. Elle imposera tout de même quelques limitations telles que l'impossibilité de facilement préciser un intervalle d'optimisation, le fait qu'elle ne pourra que minimiser la fonction étudiée et l'obligation de lui fournir des valeurs de départ. \cite{optim} \\

Parmi les arguments de la fonction \texttt{optim}, nous devrons minimalement désigner les valeurs de départ de nos paramètres avec \texttt{par} \footnote{À ne pas confondre avec la fonction permettant de contrôler l'affichage graphique \texttt{par}.} et fournir à \texttt{fn} la fonction à minimiser. Il sera possible de définir des bornes aux valeurs optimisées grâce aux arguments \texttt{lower} et \texttt{upper}. Le \autoref{src:optim} illustre une application standard de cette fonction. Vous ne serez pas surpris de rencontrer à nouveau la technique du retour multiple au sein d'une liste. De cette liste, nous utiliserons principalement les attributs \texttt{par} et \texttt{value}. Ceux-ci nous donneront accès aux paramètres optimisés et à la valeur de convergence obtenue. Il sera conseillé de garder un oeil sur \texttt{convergence} qui indiquera si l'optimisation s'est terminée de manière conforme (valeur de 0) ou que le processus d'optimisation  n’est pas parvenu à converger (valeur de 1). La valeur de \texttt{counts} témoigne du nombre d'itérations effectuées afin d'arriver aux résultats. Par défaut, la fonction \texttt{optim} arrêtera au compte de 501 itérations après quoi les valeurs actuelles de l'optimisation seront renvoyées en plaçant toutefois la valeur de l'attribut \texttt{convergence} à 1. \\

\begin{lstlisting}[caption = Optimisation générique avec R,label=src:optim]
> f1 <- function(x,y) 5*x**2 - 7*y + 10
> f2 <- function(x,y) 10*x**2 + 30*y -2
> foptim <- function(x1,x2) (f1(x1,x2) - f2(x1,x2))**2
> (results <- optim(par = c(4,5), function(par) foptim(par[1],par[2])))
$par
[1] 0.4532121 0.2968149

$value
[1] 8.385268e-05

$counts
function gradient 
      57       NA 

$convergence
[1] 0

$message
NULL

> f1(results$par[1],results$par[2])
[1] 8.949302
> f2(results$par[1],results$par[2])
[1] 8.958459
\end{lstlisting}

\vspace{\baselineskip}
Malgré le fait que nous ayons mentionné des limitations à la fonction \texttt{optim}, cela ne signifie pas pour autant que nous ne pourrons pas imaginer des manières de contourner ces dernières. En effet, une maximisation revient tout simplement à trouver la valeur minimale de l'inverse de la fonction étudiée. Ainsi, le simple ajout d'un signe de négation devant la fonction passée à l'argument \texttt{fn} nous permettra d'effectuer une maximisation plutôt qu'une minimisation. Il s'agit là de la stratégie employée dans le \autoref{src:optimMax}. \\

Il n’est pas rare que plus d’une solution soit viable aux yeux d’un processus d’optimisation dépendamment du problème étudié. Nous appelons ces nombreuses solutions des extremums locaux. C'est l'existence de ces extremums qui rend les valeurs initiales de l'optimisation si sensibles. Lorsque possible, il sera donc fortement conseillé de procéder à des techniques de validation graphique comme nous l'avons fait dans le cadre du \autoref{src:optimMax}. (Voir \autoref{fig:optimMax}) \\

\begin{lstlisting}[caption = Maximisation d'une fonction avec \texttt{optim},label=src:optimMax]
> f3 <- function(x,y) -x**2 - 2*y**2 + 3*x + 4*y - 5
> (results <- optim(par = c(0,0), function(par) -f3(par[1],par[2])))
$par
[1] 1.5001064 0.9999031

$value
[1] 0.75

$counts
function gradient 
      69       NA 

$convergence
[1] 0

$message
NULL

> # install.packages("rgl")
> library(rgl)
> persp3d(f3,xlim = c(-5,5),ylim = c(-5,5))
\end{lstlisting}

\addPicture{1}{0.5}{optim3d}{Représentation graphique de la fonction \texttt{f3}}{optimMax}

\begin{moreInfo}{Contrôler l'incontrôlable}
	Bien que vous n'aurez pas à modifier le comportement par défaut de la fonction \texttt{optim} pour parvenir à vos fins, il est important de savoir que la fonction propose plusieurs arguments qui permettent d'influencer la manière par laquelle l'optimisation sera effectuée. Nous pouvons rapidement citer les arguments \texttt{method} et \texttt{control}. Veillez vous référer à la documentation officielle pour de plus amples détails à leur sujet. \\
	\url{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/optim.html}
\end{moreInfo}

Une autre fonction d'intérêt lorsque nous travaillons avec des distributions statistiques est \texttt{fitdistr} provenant du paquetage \texttt{MASS}. Celle-ci permet de facilement ajuster une distribution donnée à un jeu de données empiriques. Évidemment, nous pourrions très bien passer par \texttt{optim} pour réaliser le même travail moyennant un certain coût de complexité. Or, ce mal sera parfois nécessaire puisque la fonction \texttt{fitdistr} n'est définie que pour les distributions suivantes : \cite{MASS}

\begin{minipage}{\linewidth}
	\begin{multicols}{2}
		\begin{itemize}
			\item Bêta
			\item Binomiale négative
			\item Cauchy
			\item Khi carrée
			\item Exponentielle
			\item F (Fisher)
			\item Gamma
			\columnbreak
			\item Géometrique
			\item Log-Normale
			\item Logistique
			\item Normale
			\item Poisson
			\item T (Student)
			\item Weibull
		\end{itemize}
	\end{multicols}
\end{minipage}
\vspace{\baselineskip}

Il arrivera donc dans certains cas que nous devrons procéder à l'ajustement des distributions par la méthode du maximum de vraisemblance directement avec \texttt{optim}. Nous prioriserons toutefois l'utilisation de \texttt{fitdistr}. \\

L'appel de \texttt{fitdistr} se fera la majorité du temps en passant un vecteur de données sur lesquelles ajuster la distribution et en précisant le nom de la distribution à ajuster. Ce qui présente un net avantage en terme de simpliciter par rapport à l'appel de la fonction \texttt{optim} qui permettra d'accomplir le même travail. Le \autoref{src:fitdistr} présente l'utilisation de ces deux méthodes. \\

\begin{lstlisting}[caption = Ajustement de distribution sur données empiriques,label=src:fitdistr]
> x <- rgamma(1000,40,3)
> optim(c(10,1),function(par) -sum(dgamma(x,par[1],par[2],log = TRUE)))
$par
[1] 37.216936  2.785522

$value
[1] 2193.865

$counts
function gradient 
      69       NA 

$convergence
[1] 0

$message
NULL

> #install.packages("MASS")
> library(MASS)
> fitdistr(x,"gamma")
     shape         rate   
  37.1275898    2.7787518 
 ( 1.6529478) ( 0.1245497)
\end{lstlisting}

Les mordus de statistiques parmi vous auront constaté que les distributions reconnues par \texttt{fitdistr} ne nécessitent pas toujours le même nombre de paramètres. Il s'agit là d'une complexité algorithmique de bonne taille. Dans le cadre de l'étude de cas, nous avons cru bon de créer une réplique de cette fonction afin d'expliquer comment nous pouvons nous y prendre pour octroyer un comportement aussi flexible. Voici pour commencer le code source de cette fameuse fonction : \\

\begin{lstlisting}[caption = Réplicat maison de la fonction \texttt{fitdistr} ,label=src:distFit]
#' Generic function for statistical distribution adjustment
#' 
#' @param data A vector of value over which we want to fit the distribution
#' @param dist The distribution name
#' @param ... The initial values to be given to the optimisation function
#' @return A list containing : 
#' the optimized parameters, 
#' the error value, 
#' the deviance measure,
#' the convergence indicator and 
#' the number of iterations necessited
#' @examples
#' x <- rnorm(1000,10,2)
#' distFit(x,"Normal", 1, 1)
#' x <- rgamma(1000,5,1)
#' distFit(x,"Gamma", 1, 1)
#' 
distFit <- function(data,dist,...)
{
  dist = tolower(dist)
  args = list(...)
  if(dist == "normal")
  {
    law = "norm"
    nbparam = 2
  }
  else if(dist == "exp")
  {
    law = "exp"
    nbparam = 1
    lower = 0
    upper = 100/mean(data)
  }
  else if(dist == "gamma")
  {
    law = "gamma"
    nbparam = 2
  }
  else if(dist == "lognormal")
  {
    law = "lnorm"
    nbparam = 2
  }
  else if(dist == "weibull")
  {
    law = "weibull"
    nbparam = 2
  }
  else if(dist == "pareto")
  {
    law = "pareto"
    nbparam = 2
  }
  else if(dist == "invgaussian")
  {
    law = "invgauss"
    nbparam = 2
  }
  else if(dist == "student")
  {
    law = "t"
    nbparam = 1
    lower = 0
    upper = 100/mean(data)
  }
  else if(dist == "burr")
  {
    law = "burr"
    nbparam = 3
  }
  else
  {
    message <- "The only distributions available are: 
    Normal, Exp, Gamma, LogNormal, Weibull, Pareto, Student, Burr and InvGaussian.
    (This case will be ignored)"
    stop(message)
  }
  if(nbparam != length(args))
  {
    message <- paste("There is a mismatch between the number of arguments passed to the 
                     function and the number of arguments needed to the distribution.",
                     "The",dist,"distribution is taking",nbparam,"parameters and",
                     length(args),"parameters were given.")
    stop(message)
  }

  # Treament
  if(nbparam == 1)
  {
    param <- optim(par = args, function(par) 
      -sum(do.call(eval(parse(text = paste("d",law,sep=""))),c(list(data),par,log = TRUE))),
      method = "Brent", lower = lower, upper = upper)
  }
  else{
    param <- optim(par = args, function(par) 
      -sum(do.call(eval(parse(text = paste("d",law,sep=""))),c(list(data),par,log = TRUE))))
  }
  # Deviance value
  devValue <- sum((empPDF(x <- seq(0,max(data),0.1))-do.call(eval(parse(text = paste("d",law,sep=""))),c(list(x),param$par)))**2)
  
  # Return List
  distFitList <- list() 
  distFitList$param <- param$par
  distFitList$errorValue <- param$value
  distFitList$devValue <- devValue
  distFitList$convergence <- param$convergence
  distFitList$nbiter <- param$counts[1]
  distFitList
}
\end{lstlisting}

Le \autoref{src:distFit} peut sembler impressionnant à première vue, mais environ 90\% de son corps ne sert qu'à faire de la gestion d'erreurs. Comme indiqué par les commentaires internes, les lignes de commandes renfermant le secret de ce type de fonction sont les suivantes: \\

\begin{minipage}{\linewidth}
	\noindent
	\texttt{param <- optim(par = args, function(par) -sum(do.call(eval(parse(text = paste("d",law,sep=""))),c(list(data),par,log = TRUE))))}
\end{minipage}

\vspace{\baselineskip}
Sans trop de précisions, la fonction \texttt{parse} permettra de créer des expressions non-évaluées. Il existe plusieurs manières de générer ces expressions. Celle employée dans le cas présent se fera à partir d'un vecteur de caractères qui nous permettra de concaténer le "d" de la fonction de densité à l'identifiant R de la distribution choisie. (Voir \autoref{tab:distStatsR} $\langle ID_R \rangle$) Une fois cette expression construite, nous pourrons la faire évaluer par R grâce à la fonction \texttt{eval} qui transformera la ligne de code en un objet (étant ici la fonction de densité de la distribution choisie). À cet objet, nous pourrons désormais lui fournir des paramètres au même titre que nous le ferions avec la fonction de densité correspondante. Alors pourquoi avons-nous senti le besoin d'utiliser \texttt{do.call}? La fonction \texttt{do.call} rend possible l'appel d'une fonction ayant un nombre d'arguments quelconque. Elle s'occupera de fournir une liste de paramètres à la fonction considérée pour autant que la fonction réceptrice accepte autant d'arguments que fournis et que les types correspondent. Étant donné que le nombre de paramètres de nos distributions peut varier, nous n'aurions pas pu envisager de créer un traitement particulier pour tous les cas possibles.

\begin{lstlisting}[caption = Exemple d'utilisation de la fonction \texttt{distFit},label=src:distFitEx]
> x <- rexp(10000,4)
> distFit(x,"Exp",1)$param
[1] 4.102991
> x <- rt(10000,5)
> distFit(x,"Student",1)$param
[1] 5.056508
> x <- rgamma(10000,4,2)
> distFit(x,"Gamma",1,1)$param
[1] 3.982845 1.981206
> x <- rburr(10000,1,10,0.01)
> distFit(x,"Burr",0.9,1,0.1)$param
[1]  0.95531981 10.09683646  0.01006351
Warning messages:
1: In (function (x, shape1, shape2, rate = 1, scale = 1/rate, log = FALSE)  :
  NaNs produced
2: In (function (x, shape1, shape2, rate = 1, scale = 1/rate, log = FALSE)  :
  NaNs produced
3: In (function (x, shape1, shape2, rate = 1, scale = 1/rate, log = FALSE)  :
  NaNs produced
4: In (function (x, shape1, shape2, rate = 1, scale = 1/rate, log = FALSE)  :
  NaNs produced
\end{lstlisting}

Comme nous venons de le voir, la combinaison de ces trois fonctions ouvre les portes à un autre niveau de flexibilité pour la définition de fonctions utilitaires. Grâce à cet exemple, nous comprenons désormais un peu mieux la mécanique sous-entendue par le passage de paramètres additionnels via l'argument \texttt{(...)}. \\

En ce qui à trait à notre étude de cas, l'ajustement de distribution fut nécessaire pour déterminer selon quelle loi les poids des colis pouvaient être modélisés. Une fois cette modélisation réalisée, il sera beaucoup plus simple de procéder à l'analyse par simulation de la \autoref{sec:simul}. La \autoref{tab:weightDistFit} consiste en un sommaire des résultats d'ajustement obtenus selon la fonction utilitaire \texttt{distFit} et la fonction \texttt{fitdistr} du paquetage \texttt{MASS}. \\

\begin{table}
	\centering
	\begin{tabular}{ccccc}
		\multirow{2}{*}{\textbf{Distribution}} & \multicolumn{2}{c}{\textbf{\texttt{distFit}}} & \multicolumn{2}{c}{\textbf{\texttt{fitdistr}}} \\
		& \textbf{$Param_1$} & \textbf{$Param_2$} & \textbf{$Param_1$} & \textbf{$Param_2$} \\
		\hline
		Gamma & 3.055112 & 0.8589427 & 3.054802645 & 0.857914221 \\
		InvGaussian & 3.560507 & 8.643489 & \texttt{NA} & \texttt{NA} \\
		LogNormal & 1.097521 & 0.5874043 & 1.097461059 & 0.587425157 \\
		Normal & 3.560237 & 2.282066 & 3.560736550 & 2.281963899 \\
		Pareto & 13 974 470 & 49 759 350 & \texttt{NA} & \texttt{NA} \\
		Weibull & 1.704325 & 4.020126 & 1.704313997 & 4.019855513 \\	
	\end{tabular}
	\caption{Ajustement de distribution sur poids observés selon la fonction utilitaire \texttt{distFit} et la fonction \texttt{fitdistr} du paquetage \texttt{MASS}}
	\label{tab:weightDistFit}
\end{table} 

\addPicture{1}{0.5}{fitDist}{Visualisation de l'ajustement sur la distribution empirique des poids (Cumulative à gauche et Densité à droite)}{fitDist}

Somme toute, les résultats de notre fonction utilitaire sont drôlement impressionnant compte tenu de la flexibilité additionnelle que nous lui avons fourni en comparaison à son homologue. De l'autre côté de la médaille, notre fonction est loin d'être optimale et pourra s'avérer peu efficace sur des plus gros jeux de données. \\

De ces résultats, nous pouvons désormais conclure que les poids suivent une loi $LogNormal(\mu := 1.0975,\sigma := 0.587)$. Nous voyons toutefois qu'une loi $InvGaussian(\mu := 3.56,\sigma := 8.64)$ aurait pu être un bon choix! Cela n'est pas une situation aussi rare qu'elle peut ne le paraître et le choix de la distribution devra s'appuyer sur d'autres considérations que coefficient d'ajustement. Nous pourrons préférer choisir une distribution avec un moins bon ajustement en raison de ses propriétés simplifiant ainsi le reste de l'analyse par exemple. En terminant, puisque nous sommes dans un contexte éducationnel et que les données ont été produites par le \autoref{src:benchmark}, il nous ai aussi possible de comparer la distribution sélectionnée avec celle qui est à l'origine de ces observations. Vous constaterez par vous même la précision de nos résultats. \\

\begin{table}
	\centering
	\begin{tabular}{cccc}
		\multicolumn{2}{c}{\textbf{Distribution Ajustée}} & \multicolumn{2}{c}{\textbf{Distribution Théorique}} \\
		\textbf{$Param_1$} & \textbf{$Param_2$} & \textbf{$Param_1$} & \textbf{$Param_2$} \\
		\hline
		$1.0975$ & $0.587$ & $\log{3} \approx 1.0986$ & $\log{1.8} \approx 0.5878$
	\end{tabular}
	\caption{Comparaison des paramètres de la distribution ajustée et théorique des poids de colis (Kg)}
	\label{tab:compareDistWeight}
\end{table}

\begin{moreInfo}{Une variable plutôt invariante...}
	Il est possible de démontrer que si $X \sim LogNormal(\mu,\sigma)$ alors $aX \sim LogNormal(\mu + \log{a},\sigma)$. C'est cette propriété qui nous permet de faire le pont entre le paramàtre $\mu$ que l'on retrouve dans le \autoref{src:benchmark} ($\log{3000}$) et la valeur théorique que l'on affiche à la \autoref{tab:compareDistWeight}. La différence provient du fait que nous avons créer notre fonction théorique en gramme pour ensuite la convertir en Kg en divisant par 1000. En applicant le postulat, nous obtenons: 
	$$\log{3000}+\log{\frac{1}{1000}} = \log{3000}-\log{1000} = \log{\frac{3000}{1000}} = \log{3}.$$
	\url{https://en.wikipedia.org/wiki/Log-normal_distribution#Related_distributions}
\end{moreInfo}